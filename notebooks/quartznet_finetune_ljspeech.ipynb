{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "YvnbraQcZRL6",
        "outputId": "cd054a22-6f91-41b8-ab85-ae326aafbaf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'quartznet-pytorch'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 196 (delta 111), reused 136 (delta 64), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (196/196), 37.48 KiB | 511.00 KiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://<login>:<pass>@github.com/oleges1/quartznet-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zJsi547FaY2C",
        "outputId": "13ad5430-ccc9-4379-85bb-ca6573c11de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from -r quartznet-pytorch/requirments.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.6/dist-packages (from -r quartznet-pytorch/requirments.txt (line 2)) (1.9)\n",
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 8.9MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/14/9a2c792e48e01e55913b9495ce0e8a16297e2bc1cc99e86a848d205c91e7/wandb-0.10.5-py2.py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 49.8MB/s \n",
            "\u001b[?25hCollecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/34/c651430dea231e382ddf2eb5773239bf4885d9528f640a4ef39b12894cb8/torchaudio-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from -r quartznet-pytorch/requirments.txt (line 6)) (0.6.3)\n",
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hCollecting audiomentations\n",
            "  Downloading https://files.pythonhosted.org/packages/14/c9/4bd1a4656487c112405bb3facb8ee106e00bad32baee79a5e4dd2c13884c/audiomentations-0.12.1-py3-none-any.whl\n",
            "Collecting pytorch_warmup\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/22/2fb600a06a1d1b493d54ac8fa6c41e96870985992fc504104e0620bc2ea4/pytorch_warmup-0.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome->-r quartznet-pytorch/requirments.txt (line 3)) (7.1.2)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r quartznet-pytorch/requirments.txt (line 4)) (5.4.8)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/08/5eb320799e3085ccc66ec0fc3360421302803f3b784f74959564dbc6cdc9/sentry_sdk-0.19.0-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r quartznet-pytorch/requirments.txt (line 4)) (3.12.4)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r quartznet-pytorch/requirments.txt (line 4)) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/d7/b2b0672e0331567157adf9281f41ee731c412ee518ca5e6552c27fa73c91/GitPython-3.1.9-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 52.5MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r quartznet-pytorch/requirments.txt (line 4)) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r quartznet-pytorch/requirments.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb->-r quartznet-pytorch/requirments.txt (line 4)) (2.8.1)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio->-r quartznet-pytorch/requirments.txt (line 5)) (1.6.0+cu101)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r quartznet-pytorch/requirments.txt (line 6)) (0.48.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->-r quartznet-pytorch/requirments.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r quartznet-pytorch/requirments.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r quartznet-pytorch/requirments.txt (line 6)) (2.1.8)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r quartznet-pytorch/requirments.txt (line 6)) (1.18.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r quartznet-pytorch/requirments.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r quartznet-pytorch/requirments.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r quartznet-pytorch/requirments.txt (line 6)) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein->-r quartznet-pytorch/requirments.txt (line 7)) (50.3.0)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb->-r quartznet-pytorch/requirments.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb->-r quartznet-pytorch/requirments.txt (line 4)) (2020.6.20)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb->-r quartznet-pytorch/requirments.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb->-r quartznet-pytorch/requirments.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchaudio->-r quartznet-pytorch/requirments.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->-r quartznet-pytorch/requirments.txt (line 6)) (0.31.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: python-Levenshtein, watchdog, subprocess32, pathtools\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144789 sha256=e81fd1e8e1d3873f1b114df1870d83097a842bb1c7f7e1c5cecaaabf903b06ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=26b17fa37705baa73c749021696a8e0c990293c80c02b9f44cadac91f53f003e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=3cde9ed6995e4d68cb1a789ec2ad34ff16d5938417695d2345cdabf707ba78cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=c302c798d01eea55d7fcd3d34d303a88647c71f4aad2eeebf7d9a7d132014656\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built python-Levenshtein watchdog subprocess32 pathtools\n",
            "Installing collected packages: youtokentome, pathtools, watchdog, sentry-sdk, smmap, gitdb, GitPython, docker-pycreds, shortuuid, subprocess32, configparser, wandb, torchaudio, python-Levenshtein, audiomentations, pytorch-warmup\n",
            "Successfully installed GitPython-3.1.9 audiomentations-0.12.1 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 python-Levenshtein-0.12.0 pytorch-warmup-0.0.4 sentry-sdk-0.19.0 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 torchaudio-0.6.0 wandb-0.10.5 watchdog-0.10.3 youtokentome-1.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install -r quartznet-pytorch/requirments.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "p4I6cyozVt5a",
        "outputId": "0596deef-a03c-431f-fc61-dd0b70f2f26d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Oct 13 14:22:35 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "fHa2U9sMsPqz",
        "outputId": "b474c307-7761-44be-c230-10fa283e1314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 1059 (delta 5), reused 7 (delta 2), pack-reused 1047\u001b[K\n",
            "Receiving objects: 100% (1059/1059), 759.79 KiB | 1.65 MiB/s, done.\n",
            "Resolving deltas: 100% (508/508), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 86, done.        \n",
            "remote: Counting objects: 100% (86/86), done.        \n",
            "remote: Compressing objects: 100% (60/60), done.        \n",
            "remote: Total 13668 (delta 39), reused 53 (delta 21), pack-reused 13582        \n",
            "Receiving objects: 100% (13668/13668), 5.53 MiB | 1.42 MiB/s, done.\n",
            "Resolving deltas: 100% (7845/7845), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "Processing /content/ctcdecode\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.2-cp36-cp36m-linux_x86_64.whl size=12592105 sha256=15f80358cca11d5847a83b6076c1ec25d8d281fd710abc28752c5237b93ec427\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cdwgpou0/wheels/c3/6c/94/7d57d4f20a87a22ef1722eaad22052b4c435892b55400e5f4e\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!cd ctcdecode && pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rb7XESIrcXyQ"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"ya.hef@yandex.ru\"\n",
        "!git config --global user.name \"oleges1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Ocsz5akwFRaI",
        "outputId": "77a1c214-efe4-4da7-e957-81736daffdf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pUlHfKPPZiAg"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "os.chdir('C:/Users/nntin/uni/fyp/quartznet-pytorch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CyrPTog-aC8W"
      },
      "outputs": [],
      "source": [
        "sys.path.append('quartznet-pytorch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9UyNGQSxbs0j"
      },
      "outputs": [],
      "source": [
        "from train import train\n",
        "import yaml\n",
        "from easydict import EasyDict as edict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DRYQ3Ox3aIM1"
      },
      "outputs": [],
      "source": [
        "with open(\"quartznet-pytorch/configs/finetune_LJSpeech.yaml\", 'r') as stream:\n",
        "    config = edict(yaml.safe_load(stream))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBy6jc8AyWaF"
      },
      "source": [
        "## Train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VMG-kRvChDOW",
        "outputId": "5403a216-ac13-4417-eed0-aedaadbcaaaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QuartzNet(\n",
            "  (encoder): Sequential(\n",
            "    (0): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(64, 64, kernel_size=(33,), stride=(2,), padding=(16,), groups=64, bias=False)\n",
            "          (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (1): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (2): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (3): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(51,), stride=(1,), padding=(25,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(51,), stride=(1,), padding=(25,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(51,), stride=(1,), padding=(25,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(51,), stride=(1,), padding=(25,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(51,), stride=(1,), padding=(25,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (4): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (5): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (6): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(87,), stride=(1,), padding=(86,), dilation=(2,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (7): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (1): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classify): Conv1d(1024, 120, kernel_size=(1,), stride=(1,))\n",
            ")\n",
            "<All keys matched successfully>\n",
            "['<PAD>', '<UNK>', '<BOS>', '<EOS>', '▁', 'e', 't', 'a', 'o', 'n', 'i', 's', 'r', 'h', 'd', 'l', 'c', 'f', 'u', 'm', 'w', 'p', 'g', 'y', 'b', 'v', 'k', 'x', 'q', 'j', 'z', 'ü', '”', '“', 'é', '’', 'ê', 'è', 'â', 'à', '▁t', 'he', '▁a', '▁the', 'in', '▁o', '▁w', 're', '▁s', 'en', 'on', 'er', 'ed', '▁c', 'at', '▁b', '▁p', '▁f', '▁of', 'nd', '▁h', 'is', 'it', '▁m', 'or', '▁in', 'as', '▁to', 'al', 'ar', 'ou', 'es', '▁and', '▁d', '▁th', 'ing', 'an', '▁n', 'ic', 'ent', 'ion', '▁l', 'ro', '▁e', '▁was', '▁he', 'ot', '▁re', 'ly', 'le', '▁be', 'ad', 'id', '▁on', 'im', 've', 'st', 'om', 'll', '▁wh', '▁that', '▁g', 'ct', 'se', 'ut', 'et', '▁for', 'gh', 'ce', '▁as', '▁u', '▁st', 'ir', 'ld', 'ere', '▁his', 'ri', 'ur', 'qu', '▁at']\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.5<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">noble-gorge-65</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/oleges/quartznet_ljspeech\" target=\"_blank\">https://wandb.ai/oleges/quartznet_ljspeech</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/oleges/quartznet_ljspeech/runs/ubvh7gvy\" target=\"_blank\">https://wandb.ai/oleges/quartznet_ljspeech/runs/ubvh7gvy</a><br/>\n",
              "                Run data is saved locally in <code>wandb/run-20201013_145242-ubvh7gvy</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [10:46:31<00:00, 1939.56s/it]\n"
          ]
        }
      ],
      "source": [
        "train(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qYKUCRNYvylK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "checkpoint_files = [item for item in os.listdir('checkpoints') if item.endswith('pth')]\n",
        "epochs = [int(file.split('_')[1]) for file in checkpoint_files]\n",
        "checkpoint_file = checkpoint_files[int(np.argmax(epochs))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "00XGQzpSdDT-"
      },
      "outputs": [],
      "source": [
        "config.model.name = '_quartznet5x5_config'\n",
        "config.train.from_checkpoint = f'checkpoints/{checkpoint_file}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "VjWpld0-x-pL",
        "outputId": "10021aa1-a612-4fc0-9aa8-00e3e71116a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.system(f'cp checkpoints/{checkpoint_file} .')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "keosR9WldPYf",
        "outputId": "8ac8530b-e1df-4f4d-e46a-95699af2d6cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from evaluate import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MVoihN-qdXyK",
        "outputId": "6eec3233-50b1-4177-ba43-5a6d7924ddd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QuartzNet(\n",
            "  (encoder): Sequential(\n",
            "    (0): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(64, 64, kernel_size=(33,), stride=(2,), padding=(16,), groups=64, bias=False)\n",
            "          (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (1): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(33,), stride=(1,), padding=(16,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (2): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(39,), stride=(1,), padding=(19,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (3): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(256, 256, kernel_size=(51,), stride=(1,), padding=(25,), groups=256, bias=False)\n",
            "          (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(51,), stride=(1,), padding=(25,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(51,), stride=(1,), padding=(25,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(51,), stride=(1,), padding=(25,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(51,), stride=(1,), padding=(25,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (4): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(63,), stride=(1,), padding=(31,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (5): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(75,), stride=(1,), padding=(37,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (9): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (6): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(87,), stride=(1,), padding=(86,), dilation=(2,), groups=512, bias=False)\n",
            "          (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (2): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (7): MainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (1): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): ReLU()\n",
            "        (1): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classify): Conv1d(1024, 120, kernel_size=(1,), stride=(1,))\n",
            ")\n",
            "<All keys matched successfully>\n",
            "['<PAD>', '<UNK>', '<BOS>', '<EOS>', '▁', 'e', 't', 'a', 'o', 'n', 'i', 's', 'r', 'h', 'd', 'l', 'c', 'f', 'u', 'm', 'w', 'p', 'g', 'y', 'b', 'v', 'k', 'x', 'q', 'j', 'z', 'ü', '”', '“', 'é', '’', 'ê', 'è', 'â', 'à', '▁t', 'he', '▁a', '▁the', 'in', '▁o', '▁w', 're', '▁s', 'en', 'on', 'er', 'ed', '▁c', 'at', '▁b', '▁p', '▁f', '▁of', 'nd', '▁h', 'is', 'it', '▁m', 'or', '▁in', 'as', '▁to', 'al', 'ar', 'ou', 'es', '▁and', '▁d', '▁th', 'ing', 'an', '▁n', 'ic', 'ent', 'ion', '▁l', 'ro', '▁e', '▁was', '▁he', 'ot', '▁re', 'ly', 'le', '▁be', 'ad', 'id', '▁on', 'im', 've', 'st', 'om', 'll', '▁wh', '▁that', '▁g', 'ct', 'se', 'ut', 'et', '▁for', 'gh', 'ce', '▁as', '▁u', '▁st', 'ir', 'ld', 'ere', '▁his', 'ri', 'ur', 'qu', '▁at']\n",
            "defaultdict(<class 'list'>, {'val_loss': 0.5264071103185415, 'wer': 0.27192559258643667, 'cer': 0.07488137021352631, 'val_samples': <wandb.data_types.Table object at 0x7f4732345668>})\n"
          ]
        }
      ],
      "source": [
        "evaluate(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "yQ0TRgtfhgAF",
        "outputId": "acd9c6e3-83bd-48c0-cf22-b2b8a01b3623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/oleges1/quartznet-pytorch\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   0045b9a..29fcf7b  main       -> origin/main\n",
            "Updating 0045b9a..29fcf7b\n",
            "Fast-forward\n",
            " README.md | 1 \u001b[32m+\u001b[m\n",
            " 1 file changed, 1 insertion(+)\n"
          ]
        }
      ],
      "source": [
        "!cd quartznet-pytorch && git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "NzxMfO8uck3s"
      },
      "outputs": [],
      "source": [
        "!cd quartznet-pytorch && git add ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "JEjKZ9sEmVly",
        "outputId": "f40e7d67-c521-4c0c-da76-64485c8533be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[main 8b2748a] eval -> evaluate, bugfixes\n",
            " 1 file changed, 7 insertions(+)\n",
            " rename eval.py => evaluate.py (94%)\n"
          ]
        }
      ],
      "source": [
        "!cd quartznet-pytorch && git commit -m \"eval -> evaluate, bugfixes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "KfisxXPQcF-u",
        "outputId": "4905a7f3-0c21-49fb-e90f-703bebfc85c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counting objects: 3, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  33% (1/3)   \rCompressing objects:  66% (2/3)   \rCompressing objects: 100% (3/3)   \rCompressing objects: 100% (3/3), done.\n",
            "Writing objects:  33% (1/3)   \rWriting objects:  66% (2/3)   \rWriting objects: 100% (3/3)   \rWriting objects: 100% (3/3), 1.70 KiB | 1.70 MiB/s, done.\n",
            "Total 3 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/oleges1/quartznet-pytorch.git\n",
            "   4ab1d12..8b2748a  main -> main\n"
          ]
        }
      ],
      "source": [
        "!cd quartznet-pytorch && git push origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "5Nz0Tj_qU7sq",
        "outputId": "d83e629a-6d34-4795-9ded-79af89d3a127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".\t\t\t\t  model_17_0.2841321284154134.pth\n",
            "..\t\t\t\t  model_2_0.42167072621412405.pth\n",
            "model_0_0.4302549583938145.pth\t  model_3_0.3995134516324537.pth\n",
            "model_10_0.3215405433199863.pth   model_4_0.38728194926547643.pth\n",
            "model_1_0.42616296580235646.pth   model_5_0.36995034137678906.pth\n",
            "model_11_0.3097812508179529.pth   model_6_0.36059540547701313.pth\n",
            "model_12_0.30095886475545636.pth  model_7_0.34674579977343695.pth\n",
            "model_13_0.2954691471587973.pth   model_8_0.34120389584236915.pth\n",
            "model_14_0.29511776741055046.pth  model_9_0.3318550738096163.pth\n",
            "model_15_0.28474790346010614.pth\n"
          ]
        }
      ],
      "source": [
        "!ls -a checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "v4YDiWNX1dyW",
        "outputId": "4826a7e0-62c2-4155-8c97-f0fb7c16d406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'checkpoints': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! rm -r wandb \n",
        "! rm -r checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOiBhdjFVEiz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "quartznet_finetune_ljspeech.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
