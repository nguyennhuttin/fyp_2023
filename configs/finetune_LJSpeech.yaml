dataset:
  root: DB/LJspeech
  train_part: 0.95
  name: ljspeech
  sample_rate: 22050
bpe:
  train: true
  model_path: yttm.bpe
train:
  seed: 42
  num_workers: 16
  batch_size: 32
  clip_grad_norm: 15
  epochs: 20
  optimizer:
    lr: 0.0005 # 0.0003 - Karpathy great constant for Adam
    weight_decay: 0.0001 # leave default
  from_checkpoint: model_36_0.36604105617182675.pth
wandb:
  project: quartznet_ljspeech
  log_interval: 20
model:
  name: _quartznet5x5_config
  vocab_size: 120
  feat_in: 64
  # init_mode: kaiming_normal
